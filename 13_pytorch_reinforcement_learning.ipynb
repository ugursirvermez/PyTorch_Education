{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOch1AFrF9FTfKIe0519tT4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ugursirvermez/PyTorch_Education/blob/main/13_pytorch_reinforcement_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Kurulumlar"
      ],
      "metadata": {
        "id": "hfgg3lUPWVj0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-uDp68mxWQNv",
        "outputId": "0b11c493-150a-4570-89fc-75c5f83ebcb0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gym in /usr/local/lib/python3.11/dist-packages (0.25.2)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.11/dist-packages (from gym) (1.26.4)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gym) (3.1.1)\n",
            "Requirement already satisfied: gym_notices>=0.0.4 in /usr/local/lib/python3.11/dist-packages (from gym) (0.0.8)\n",
            "Requirement already satisfied: atari-py in /usr/local/lib/python3.11/dist-packages (0.2.9)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from atari-py) (1.26.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from atari-py) (1.17.0)\n",
            "Collecting box2d-py\n",
            "  Using cached box2d-py-2.3.8.tar.gz (374 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: box2d-py\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for box2d-py (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for box2d-py\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[?25h  Running setup.py clean for box2d-py\n",
            "Failed to build box2d-py\n",
            "\u001b[31mERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (box2d-py)\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Collecting tensorflow-gpu\n",
            "  Using cached tensorflow-gpu-2.12.0.tar.gz (2.6 kB)\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n"
          ]
        }
      ],
      "source": [
        "# Reinforcement Learning için ihtiyacımız olan kütüphaneler\n",
        "!pip3 install gym\n",
        "!pip3 install atari-py\n",
        "!pip3 install box2d-py\n",
        "!pip3 install torch\n",
        "!pip3 install tensorflow-gpu #PyTorch yerine kullanılır."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DEEPQ NETWORK Sınıfını Oluşturma"
      ],
      "metadata": {
        "id": "FFr29jatX8vw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch as T\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F #CNN ve Non_linear fonksiyonlar burada\n",
        "import torch.optim as optim #Optimizer ve Loss fonksiyonları burada hatırlayalım.\n",
        "import numpy as np\n",
        "\n",
        "# DeepQ Learning Sınıfı Oluşturalım.\n",
        "class DeepQNetwork(nn.Module):\n",
        "\n",
        "\t#Sınıf başlatıldığında neler olacak?\n",
        "\tdef __init___(self, ALPHA): #ALPHA = Learning Rate\n",
        "\t\tsuper(DeepQNetwork, self).__init__()\n",
        "\t\t#Burada iki tane evrişimsel ağ kurulacak.\n",
        "\t\tself.conv1 = nn.Conv2d(1, 32, 8, stride=4, padding=1) # (self, in_channels, out_channels, kernel_size, stride)\n",
        "\t\tself.conv2 = nn.Conv2d(32, 64, 4, stride=3) #ikiye katlandı.\n",
        "\t\tself.conv3 = nn.Conv2d(64,128,3) #Out çıktı.\n",
        "\t\tself.fc1 = nn.Linear(128*19*8, 512) #Boyutların çıktısı\n",
        "\t\tself.fc2 = nn.Linear(512, 6)\n",
        "\n",
        "\t\t#Loss ve Optimizer\n",
        "\t\tself.optimizer = optim.RMSprop(self.parameters(), lr=ALPHA)\n",
        "\t\tself.loss = nn.MSELoss()\n",
        "\n",
        "\t\t#Device GPU ? CPU\n",
        "\t\tself.device = T.device('cuda:0' if T.cuda.is_available() else 'cpu')\n",
        "\t\tself.to(self.device)\n",
        "\n",
        "\t#Forward Fonksiyonu\n",
        "\tdef forward(self, observation): #gözlemler yaparak doğru çıktıya ulaşma çabası\n",
        "\t\tobservation = T.Tensor(observation).to(self.device) #Gözlemleri CNN için Tensör haline getiriyoruz.\n",
        "\t\tobservation = observation.view(-1, 1, 185, 95)\n",
        "\t\tobservation = F.relu(self.conv1(observation)) #ReLU işlemini hatırlayalım.\n",
        "\t\tobservation = F.relu(self.conv2(observation))\n",
        "\t\tobservation = F.relu(self.conv3(observation))\n",
        "\t\tobservation = observation.view(-1,128*19*8)\n",
        "\t\tobservation = F.relu(self.fc1(observation))\n",
        "\n",
        "\t\tactions = self.fc2(observation)\n",
        "\n",
        "\t\treturn actions"
      ],
      "metadata": {
        "id": "3tlie_6KX8YW"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Agent Sınıfı -> Eğitilecek Birim"
      ],
      "metadata": {
        "id": "H_JdBFAUnWZ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Agent Sınıfı\n",
        "class Agent(object):\n",
        "\tdef __init__(self, gamma, epsilon, alpha, maxMemorySize, epsEnd=0.05,\n",
        "\t\t\t\t\t\t\t replace=10000, actionSpace=[0,1,2,3,4,5]):\n",
        "\t\t#\n",
        "\t\tself.GAMME = gamma\n",
        "\t\tself.EPSILON =epsilon\n",
        "\t\tself.EPS_END =epsEnd\n",
        "\t\tself.actionSpace = actionSpace\n",
        "\t\tself.memSize = maxMemorySize\n",
        "\t\tself.steps = 0\n",
        "\t\tself.learn_step_counter = 0\n",
        "\t\tself.memory = []\n",
        "\t\tself.memCntr = 0\n",
        "\t\tself.replace_target_cnt = replace\n",
        "\t\tself.Q_eval = DeepQNetwork(alpha)\n",
        "\t\tself.Q_next = DeepQNetwork(alpha)\n",
        "\n",
        "\t#Dönüşümleri yani bilgiler arası geçişleri saklama\n",
        "\tdef storeTransition(self, state, action, reward, state_):\n",
        "\t\tif self.memCntr < self.memSize:\n",
        "\t\t\tself.memory.append([state, action, reward, state_])\n",
        "\t\telse:\n",
        "\t\t\tself.memory[self.memCntr % self.memSize] = [state, action, reward, state_]\n",
        "\t\tself.memCntr +=1\n",
        "\n",
        "\t#Aksiyonları seçme\n",
        "\tdef chooseAction(self, observation):\n",
        "\t\trand = np.random.random()\n",
        "\t\tactions = self.Q_eval.forward(observation)\n",
        "\t\tif rand < 1 - self.EPSILON:\n",
        "\t\t\taction = T.argmax(actions[1]).item()\n",
        "\t\telse:\n",
        "\t\t\taction = np.random.choice(self.actionSpace)\n",
        "\t\tself.steps += 1\n",
        "\t\treturn action\n",
        "\n",
        "\t#Öğrenme Fonksiyonu Geliştirme\n",
        "\tdef learn(self, batch_size):\n",
        "    #her bir öğrenme adımında mevcut değeri hedeflenen değer ile karşılaştırma.\n",
        "\t\tself.Q_eval.optimizer.zero_grad() # Optimizer kullanıyoruz ama eğrimiz sıfıra oluaşmalı\n",
        "\t\tif self.replace_target_cnt is not None and \\\n",
        "\t\t\tself.learn_step_counter % self.replace_target_cnt == 0:\n",
        "\t\t\tself.Q_next.load_state_dict(self.Q_eval.state_dict())\n",
        "\n",
        "\t\t#Hafızadaki değeri ölçme\n",
        "\t\tif self.memCntr + batch_size < self.memSize:\n",
        "\t\t\tmemStart = int(np.random.choice(range(self.memCntr)))\n",
        "\t\telse:\n",
        "\t\t\tmemStart = int(np.random.choice(range(self.memCntr-batch_size-1)))\n",
        "\n",
        "\t\t#Tahmini yürütme ve sonraki hamleyi hazırlama\n",
        "\t\tminiBatch = self.memory[memStart:memStart+batch_size]\n",
        "\t\tmemory = np.array(miniBatch)\n",
        "\t\tQpred = self.Q_eval.forward(list(memory[:, 0][:])).to(self.Q_eval.device)\n",
        "\t\tQnext = self.Q_next.forward(list(memory[:, 3][:])).to(self.Q_eval.device)\n",
        "\n",
        "\t\t#Eylem sonucu nasıl oldu? Ödül mü?\n",
        "\t\tmaxA = T.argmax(Qnext, dim=1).to(self.Q_eval.device)\n",
        "\t\trewards = T.Tensor(list(memory[:, 2][:])).to(self.Q_eval.device)\n",
        "\t\tQtarget[:, maxA] = rewards + self.GAMMA*T.max(Qnext[1])\n",
        "\n",
        "\t\t#İşlem adımı\n",
        "\t\tif self.steps > 500:\n",
        "\t\t\tif self.EPSILON - 1e-4 > self.EPS_END:\n",
        "\t\t\t\tself.EPSILON -= 1e-4\n",
        "\t\t\telse:\n",
        "\t\t\t\tself.EPSILON = self.EPS_END\n",
        "\n",
        "\t\tlos = self.Q_eval.loss(Qtarget, Qpred).to(self.Q_eval.device)\n",
        "\t\tloss.backward()\n",
        "\t\tself.Q_eval.optimizer.step().self.learn_step_counter += 1"
      ],
      "metadata": {
        "id": "fRpdZI4AnWJs"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##MainLoop Oluşturma"
      ],
      "metadata": {
        "id": "zqdhQHoX3eDJ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p26oa2z_3ekg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}